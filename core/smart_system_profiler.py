#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Smart System Profiler - SystÃ¨me de profiling intelligent et adaptatif
DÃ©couvre dynamiquement les capacitÃ©s systÃ¨me sans hardcoding
"""

import sys
import os
import platform
import psutil
import time
import json
import logging
import subprocess
import threading
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, asdict
from datetime import datetime
import hashlib

@dataclass
class SystemCapabilities:
    """Structure des capacitÃ©s systÃ¨me dÃ©couvertes"""
    python_profile: Dict[str, Any]
    hardware_profile: Dict[str, Any]
    memory_profile: Dict[str, Any]
    gpu_profile: Dict[str, Any]
    thermal_profile: Dict[str, Any]
    storage_profile: Dict[str, Any]
    network_profile: Dict[str, Any]
    user_context: Dict[str, Any]
    performance_score: float
    adaptation_recommendations: List[str]

class SmartLogger:
    """SystÃ¨me de logging professionnel avec diagnostic intelligent"""
    
    def __init__(self, log_dir: str = "logs"):
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)
        
        # Configuration logging professionnel
        self.setup_logging()
        
        # MÃ©triques de performance
        self.performance_metrics = []
        self.error_patterns = {}
        
    def setup_logging(self):
        """Configure le systÃ¨me de logging professionnel"""
        log_format = '%(asctime)s | %(levelname)8s | %(name)20s | %(funcName)15s:%(lineno)4d | %(message)s'
        
        # Logger principal
        logging.basicConfig(
            level=logging.INFO,
            format=log_format,
            handlers=[
                logging.FileHandler(self.log_dir / f"system_profiler_{datetime.now().strftime('%Y%m%d')}.log"),
                logging.StreamHandler(sys.stdout)
            ]
        )
        
        self.logger = logging.getLogger("SmartSystemProfiler")
        
        # Logger sÃ©parÃ© pour les mÃ©triques
        self.metrics_logger = logging.getLogger("PerformanceMetrics")
        metrics_handler = logging.FileHandler(self.log_dir / f"performance_metrics_{datetime.now().strftime('%Y%m%d')}.log")
        metrics_handler.setFormatter(logging.Formatter('%(asctime)s | METRICS | %(message)s'))
        self.metrics_logger.addHandler(metrics_handler)
        self.metrics_logger.setLevel(logging.INFO)
        
    def log_system_analysis(self, phase: str, analysis_result: Dict, success: bool = True):
        """Logs dÃ©taillÃ©s pour diagnostic prÃ©cis"""
        status = "âœ… SUCCESS" if success else "âŒ FAILED"
        self.logger.info(f"{status} | {phase} | {json.dumps(analysis_result, indent=2)}")
        
    def log_adaptation_decision(self, decision: str, reasoning: Dict, confidence: float):
        """Trace les dÃ©cisions d'adaptation avec justification"""
        self.logger.info(f"ğŸ¯ ADAPTATION | Decision: {decision} | Confidence: {confidence:.2f} | Reasoning: {reasoning}")
        
    def log_performance_metrics(self, metrics: Dict):
        """MÃ©triques de performance pour optimisation"""
        self.metrics_logger.info(json.dumps(metrics))
        self.performance_metrics.append({
            "timestamp": datetime.now().isoformat(),
            "metrics": metrics
        })
        
    def log_error_with_context(self, error: Exception, context: Dict):
        """Log d'erreur avec contexte pour diagnostic"""
        error_hash = hashlib.md5(str(error).encode()).hexdigest()[:8]
        
        if error_hash not in self.error_patterns:
            self.error_patterns[error_hash] = {"count": 0, "first_seen": datetime.now()}
        
        self.error_patterns[error_hash]["count"] += 1
        self.error_patterns[error_hash]["last_seen"] = datetime.now()
        
        self.logger.error(f"âŒ ERROR #{error_hash} | {type(error).__name__}: {error} | Context: {context}")

class SmartSystemProfiler:
    """DÃ©couvre dynamiquement les capacitÃ©s systÃ¨me rÃ©elles"""
    
    def __init__(self):
        self.logger = SmartLogger()
        self.capabilities_cache = {}
        self.benchmark_cache = {}
        
    def discover_system_capabilities(self) -> SystemCapabilities:
        """Point d'entrÃ©e principal - dÃ©couvre toutes les capacitÃ©s systÃ¨me"""
        self.logger.log_system_analysis("DISCOVERY_START", {"action": "Starting system capabilities discovery"})
        
        start_time = time.time()
        
        try:
            # DÃ©couverte par phases avec gestion d'erreurs
            python_profile = self._discover_python_capabilities()
            hardware_profile = self._discover_hardware_capabilities()
            memory_profile = self._discover_memory_capabilities()
            gpu_profile = self._discover_gpu_capabilities()
            thermal_profile = self._discover_thermal_capabilities()
            storage_profile = self._discover_storage_capabilities()
            network_profile = self._discover_network_capabilities()
            user_context = self._analyze_user_context()
            
            # Calcul du score de performance global
            performance_score = self._calculate_performance_score({
                "hardware": hardware_profile,
                "memory": memory_profile,
                "gpu": gpu_profile,
                "storage": storage_profile
            })
            
            # GÃ©nÃ©ration des recommandations d'adaptation
            recommendations = self._generate_adaptation_recommendations({
                "python": python_profile,
                "hardware": hardware_profile,
                "memory": memory_profile,
                "gpu": gpu_profile,
                "performance_score": performance_score
            })
            
            capabilities = SystemCapabilities(
                python_profile=python_profile,
                hardware_profile=hardware_profile,
                memory_profile=memory_profile,
                gpu_profile=gpu_profile,
                thermal_profile=thermal_profile,
                storage_profile=storage_profile,
                network_profile=network_profile,
                user_context=user_context,
                performance_score=performance_score,
                adaptation_recommendations=recommendations
            )
            
            discovery_time = time.time() - start_time
            self.logger.log_performance_metrics({
                "discovery_time_seconds": discovery_time,
                "performance_score": performance_score,
                "capabilities_count": len(asdict(capabilities))
            })
            
            self.logger.log_system_analysis("DISCOVERY_COMPLETE", {
                "performance_score": performance_score,
                "discovery_time": f"{discovery_time:.2f}s",
                "recommendations_count": len(recommendations)
            })
            
            return capabilities
            
        except Exception as e:
            self.logger.log_error_with_context(e, {"phase": "system_discovery"})
            # Retourner des capacitÃ©s minimales en cas d'erreur
            return self._get_fallback_capabilities()
    
    def _discover_python_capabilities(self) -> Dict[str, Any]:
        """DÃ©couvre les capacitÃ©s Python rÃ©elles (pas de hardcoding de version)"""
        try:
            python_info = {
                "version": {
                    "major": sys.version_info.major,
                    "minor": sys.version_info.minor,
                    "micro": sys.version_info.micro,
                    "full": sys.version,
                    "version_string": f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}"
                },
                "implementation": platform.python_implementation(),
                "compiler": platform.python_compiler(),
                "executable": sys.executable,
                "platform": sys.platform,
                "architecture": platform.architecture(),
                "capabilities": self._test_python_capabilities()
            }
            
            # Test de compatibilitÃ© intelligent (pas de version hardcodÃ©e)
            compatibility = self._assess_python_compatibility(python_info)
            python_info["compatibility"] = compatibility
            
            self.logger.log_system_analysis("PYTHON_DISCOVERY", python_info)
            return python_info
            
        except Exception as e:
            self.logger.log_error_with_context(e, {"phase": "python_discovery"})
            return {"version": {"major": 3, "minor": 8}, "compatibility": {"score": 0.5, "issues": ["Discovery failed"]}}
    
    def _test_python_capabilities(self) -> Dict[str, bool]:
        """Teste les capacitÃ©s Python rÃ©elles"""
        capabilities = {}
        
        # Test des modules critiques
        test_modules = [
            "tkinter", "threading", "multiprocessing", "sqlite3",
            "json", "pathlib", "dataclasses", "typing"
        ]
        
        for module in test_modules:
            try:
                __import__(module)
                capabilities[f"has_{module}"] = True
            except ImportError:
                capabilities[f"has_{module}"] = False
        
        # Test des fonctionnalitÃ©s avancÃ©es
        try:
            import asyncio
            capabilities["has_asyncio"] = True
        except ImportError:
            capabilities["has_asyncio"] = False
        
        # Test performance basique
        start_time = time.time()
        sum(range(100000))  # Test calcul simple
        capabilities["basic_performance_ms"] = (time.time() - start_time) * 1000
        
        return capabilities
    
    def _assess_python_compatibility(self, python_info: Dict) -> Dict[str, Any]:
        """Ã‰value la compatibilitÃ© Python de maniÃ¨re intelligente"""
        version = python_info["version"]
        capabilities = python_info["capabilities"]
        
        # Score de compatibilitÃ© basÃ© sur les capacitÃ©s rÃ©elles
        compatibility_score = 1.0
        issues = []
        recommendations = []
        
        # VÃ©rification des modules critiques
        critical_modules = ["tkinter", "threading", "sqlite3", "json"]
        missing_critical = [mod for mod in critical_modules if not capabilities.get(f"has_{mod}", False)]
        
        if missing_critical:
            compatibility_score -= 0.3
            issues.append(f"Missing critical modules: {missing_critical}")
            recommendations.append("Install missing Python modules")
        
        # Ã‰valuation performance
        perf_ms = capabilities.get("basic_performance_ms", 1000)
        if perf_ms > 100:  # Performance trÃ¨s lente
            compatibility_score -= 0.2
            issues.append("Slow Python performance detected")
            recommendations.append("Consider Python optimization or hardware upgrade")
        
        # Bonus pour versions rÃ©centes (sans hardcoding strict)
        if version["major"] >= 3 and version["minor"] >= 9:
            compatibility_score += 0.1
            recommendations.append("Modern Python version - excellent compatibility")
        
        return {
            "score": max(0.0, min(1.0, compatibility_score)),
            "issues": issues,
            "recommendations": recommendations,
            "is_compatible": compatibility_score >= 0.7
        }
    
    def _discover_hardware_capabilities(self) -> Dict[str, Any]:
        """DÃ©couvre les capacitÃ©s hardware par benchmarking rÃ©el"""
        try:
            # Informations systÃ¨me de base
            hardware_info = {
                "cpu": {
                    "name": platform.processor(),
                    "architecture": platform.machine(),
                    "cores_physical": psutil.cpu_count(logical=False),
                    "cores_logical": psutil.cpu_count(logical=True),
                    "frequency": psutil.cpu_freq()._asdict() if psutil.cpu_freq() else None
                },
                "system": {
                    "platform": platform.system(),
                    "release": platform.release(),
                    "version": platform.version(),
                    "machine": platform.machine(),
                    "node": platform.node()
                }
            }
            
            # Benchmark performance CPU rÃ©el
            cpu_benchmark = self._benchmark_cpu_performance()
            hardware_info["cpu"]["benchmark"] = cpu_benchmark
            
            # Score de performance calculÃ©
            performance_score = self._calculate_cpu_performance_score(cpu_benchmark)
            hardware_info["cpu"]["performance_score"] = performance_score
            
            self.logger.log_system_analysis("HARDWARE_DISCOVERY", hardware_info)
            return hardware_info
            
        except Exception as e:
            self.logger.log_error_with_context(e, {"phase": "hardware_discovery"})
            return {"cpu": {"cores_logical": 4, "performance_score": 0.5}}
    
    def _benchmark_cpu_performance(self) -> Dict[str, float]:
        """Benchmark CPU rÃ©el (pas de suppositions)"""
        benchmarks = {}
        
        try:
            # Test calcul intensif
            start_time = time.time()
            result = sum(i * i for i in range(1000000))
            benchmarks["compute_intensive_ms"] = (time.time() - start_time) * 1000
            
            # Test utilisation CPU actuelle
            cpu_percent_samples = []
            for _ in range(5):
                cpu_percent_samples.append(psutil.cpu_percent(interval=0.1))
            benchmarks["current_cpu_usage"] = sum(cpu_percent_samples) / len(cpu_percent_samples)
            
            # Test mÃ©moire/CPU
            start_time = time.time()
            data = [i for i in range(100000)]
            data.sort()
            benchmarks["memory_cpu_ms"] = (time.time() - start_time) * 1000
            
        except Exception as e:
            self.logger.log_error_with_context(e, {"phase": "cpu_benchmark"})
            benchmarks = {"compute_intensive_ms": 1000, "current_cpu_usage": 50}
        
        return benchmarks
    
    def _calculate_cpu_performance_score(self, benchmark: Dict[str, float]) -> float:
        """Calcule un score de performance CPU normalisÃ©"""
        try:
            # Score basÃ© sur les benchmarks rÃ©els
            compute_score = max(0, 1 - (benchmark.get("compute_intensive_ms", 1000) / 2000))
            usage_score = max(0, 1 - (benchmark.get("current_cpu_usage", 50) / 100))
            memory_score = max(0, 1 - (benchmark.get("memory_cpu_ms", 1000) / 1000))
            
            # Score pondÃ©rÃ©
            overall_score = (compute_score * 0.5 + usage_score * 0.3 + memory_score * 0.2)
            return min(1.0, max(0.0, overall_score))
            
        except Exception:
            return 0.5  # Score neutre en cas d'erreur
    
    def _discover_memory_capabilities(self) -> Dict[str, Any]:
        """DÃ©couvre les capacitÃ©s mÃ©moire rÃ©elles"""
        try:
            memory = psutil.virtual_memory()
            swap = psutil.swap_memory()
            
            memory_info = {
                "virtual": {
                    "total_gb": memory.total / (1024**3),
                    "available_gb": memory.available / (1024**3),
                    "used_gb": memory.used / (1024**3),
                    "percentage": memory.percent
                },
                "swap": {
                    "total_gb": swap.total / (1024**3),
                    "used_gb": swap.used / (1024**3),
                    "percentage": swap.percent
                }
            }
            
            # Test performance mÃ©moire
            memory_benchmark = self._benchmark_memory_performance()
            memory_info["benchmark"] = memory_benchmark
            
            # Recommandations basÃ©es sur l'usage rÃ©el
            memory_info["recommendations"] = self._generate_memory_recommendations(memory_info)
            
            self.logger.log_system_analysis("MEMORY_DISCOVERY", memory_info)
            return memory_info
            
        except Exception as e:
            self.logger.log_error_with_context(e, {"phase": "memory_discovery"})
            return {"virtual": {"total_gb": 8, "available_gb": 4, "percentage": 50}}
    
    def _benchmark_memory_performance(self) -> Dict[str, float]:
        """Benchmark performance mÃ©moire"""
        benchmarks = {}
        
        try:
            # Test allocation/libÃ©ration mÃ©moire
            start_time = time.time()
            large_list = [i for i in range(1000000)]
            allocation_time = time.time() - start_time
            
            start_time = time.time()
            del large_list
            deallocation_time = time.time() - start_time
            
            benchmarks["allocation_ms"] = allocation_time * 1000
            benchmarks["deallocation_ms"] = deallocation_time * 1000
            
        except Exception as e:
            self.logger.log_error_with_context(e, {"phase": "memory_benchmark"})
            benchmarks = {"allocation_ms": 100, "deallocation_ms": 10}
        
        return benchmarks
    
    def _discover_gpu_capabilities(self) -> Dict[str, Any]:
        """DÃ©couvre les capacitÃ©s GPU de maniÃ¨re intelligente"""
        gpu_info = {"available": False, "type": "none", "capabilities": {}}
        
        try:
            # Tentative dÃ©tection NVIDIA
            try:
                import pynvml
                pynvml.nvmlInit()
                device_count = pynvml.nvmlDeviceGetCount()
                
                if device_count > 0:
                    handle = pynvml.nvmlDeviceGetHandleByIndex(0)
                    name = pynvml.nvmlDeviceGetName(handle).decode()
                    memory_info = pynvml.nvmlDeviceGetMemoryInfo(handle)
                    
                    gpu_info = {
                        "available": True,
                        "type": "nvidia",
                        "name": name,
                        "memory_total_gb": memory_info.total / (1024**3),
                        "memory_free_gb": memory_info.free / (1024**3),
                        "capabilities": {"cuda": True, "compute_capability": "unknown"}
                    }
                    
            except ImportError:
                # Pas de pynvml, essayer d'autres mÃ©thodes
                pass
            
            # Tentative dÃ©tection via subprocess (nvidia-smi)
            if not gpu_info["available"]:
                try:
                    result = subprocess.run(["nvidia-smi", "--query-gpu=name,memory.total", "--format=csv,noheader,nounits"], 
                                          capture_output=True, text=True, timeout=5)
                    if result.returncode == 0 and result.stdout.strip():
                        lines = result.stdout.strip().split('\n')
                        if lines:
                            parts = lines[0].split(', ')
                            gpu_info = {
                                "available": True,
                                "type": "nvidia",
                                "name": parts[0],
                                "memory_total_gb": float(parts[1]) / 1024 if len(parts) > 1 else 0,
                                "capabilities": {"cuda": True}
                            }
                except (subprocess.TimeoutExpired, subprocess.CalledProcessError, FileNotFoundError):
                    pass
            
            # Test capacitÃ©s GPU si disponible
            if gpu_info["available"]:
                gpu_benchmark = self._benchmark_gpu_performance()
                gpu_info["benchmark"] = gpu_benchmark
            
            self.logger.log_system_analysis("GPU_DISCOVERY", gpu_info)
            return gpu_info
            
        except Exception as e:
            self.logger.log_error_with_context(e, {"phase": "gpu_discovery"})
            return gpu_info
    
    def _benchmark_gpu_performance(self) -> Dict[str, Any]:
        """Benchmark GPU si possible"""
        try:
            # Test basique avec PyTorch si disponible
            try:
                import torch
                if torch.cuda.is_available():
                    device = torch.device("cuda")
                    
                    # Test simple
                    start_time = time.time()
                    x = torch.randn(1000, 1000, device=device)
                    y = torch.matmul(x, x)
                    torch.cuda.synchronize()
                    gpu_compute_time = time.time() - start_time
                    
                    return {
                        "pytorch_available": True,
                        "compute_test_ms": gpu_compute_time * 1000,
                        "device_name": torch.cuda.get_device_name(0)
                    }
            except ImportError:
                pass
            
            return {"pytorch_available": False, "note": "No GPU benchmark available"}
            
        except Exception as e:
            self.logger.log_error_with_context(e, {"phase": "gpu_benchmark"})
            return {"error": "GPU benchmark failed"}
    
    def _discover_thermal_capabilities(self) -> Dict[str, Any]:
        """DÃ©couvre les contraintes thermiques"""
        thermal_info = {"monitoring_available": False}
        
        try:
            # Tentative lecture tempÃ©ratures
            if hasattr(psutil, "sensors_temperatures"):
                temps = psutil.sensors_temperatures()
                if temps:
                    thermal_info["monitoring_available"] = True
                    thermal_info["sensors"] = {}
                    
                    for name, entries in temps.items():
                        thermal_info["sensors"][name] = [
                            {"label": entry.label, "current": entry.current, "high": entry.high, "critical": entry.critical}
                            for entry in entries
                        ]
            
            self.logger.log_system_analysis("THERMAL_DISCOVERY", thermal_info)
            return thermal_info
            
        except Exception as e:
            self.logger.log_error_with_context(e, {"phase": "thermal_discovery"})
            return thermal_info
    
    def _discover_storage_capabilities(self) -> Dict[str, Any]:
        """DÃ©couvre les capacitÃ©s de stockage"""
        try:
            storage_info = {"disks": []}
            
            # Informations disques
            for partition in psutil.disk_partitions():
                try:
                    usage = psutil.disk_usage(partition.mountpoint)
                    storage_info["disks"].append({
                        "device": partition.device,
                        "mountpoint": partition.mountpoint,
                        "fstype": partition.fstype,
                        "total_gb": usage.total / (1024**3),
                        "used_gb": usage.used / (1024**3),
                        "free_gb": usage.free / (1024**3),
                        "percentage": (usage.used / usage.total) * 100
                    })
                except PermissionError:
                    continue
            
            # Test performance I/O basique
            storage_benchmark = self._benchmark_storage_performance()
            storage_info["benchmark"] = storage_benchmark
            
            self.logger.log_system_analysis("STORAGE_DISCOVERY", storage_info)
            return storage_info
            
        except Exception as e:
            self.logger.log_error_with_context(e, {"phase": "storage_discovery"})
            return {"disks": [], "benchmark": {"error": "Storage discovery failed"}}
    
    def _benchmark_storage_performance(self) -> Dict[str, float]:
        """Benchmark performance stockage"""
        try:
            # Test Ã©criture/lecture fichier temporaire
            test_file = Path("temp_benchmark_file.tmp")
            test_data = b"0" * (1024 * 1024)  # 1MB
            
            # Test Ã©criture
            start_time = time.time()
            with open(test_file, "wb") as f:
                f.write(test_data)
                f.flush()
                os.fsync(f.fileno())
            write_time = time.time() - start_time
            
            # Test lecture
            start_time = time.time()
            with open(test_file, "rb") as f:
                data = f.read()
            read_time = time.time() - start_time
            
            # Nettoyage
            test_file.unlink(missing_ok=True)
            
            return {
                "write_speed_mbps": 1 / write_time if write_time > 0 else 0,
                "read_speed_mbps": 1 / read_time if read_time > 0 else 0,
                "write_time_ms": write_time * 1000,
                "read_time_ms": read_time * 1000
            }
            
        except Exception as e:
            self.logger.log_error_with_context(e, {"phase": "storage_benchmark"})
            return {"error": "Storage benchmark failed"}
    
    def _discover_network_capabilities(self) -> Dict[str, Any]:
        """DÃ©couvre les capacitÃ©s rÃ©seau"""
        try:
            network_info = {"interfaces": []}
            
            # Informations interfaces rÃ©seau
            for interface, addrs in psutil.net_if_addrs().items():
                interface_info = {"name": interface, "addresses": []}
                
                for addr in addrs:
                    interface_info["addresses"].append({
                        "family": str(addr.family),
                        "address": addr.address,
                        "netmask": addr.netmask,
                        "broadcast": addr.broadcast
                    })
                
                network_info["interfaces"].append(interface_info)
            
            # Statistiques rÃ©seau
            net_stats = psutil.net_io_counters()
            if net_stats:
                network_info["stats"] = {
                    "bytes_sent": net_stats.bytes_sent,
                    "bytes_recv": net_stats.bytes_recv,
                    "packets_sent": net_stats.packets_sent,
                    "packets_recv": net_stats.packets_recv
                }
            
            self.logger.log_system_analysis("NETWORK_DISCOVERY", network_info)
            return network_info
            
        except Exception as e:
            self.logger.log_error_with_context(e, {"phase": "network_discovery"})
            return {"interfaces": [], "error": "Network discovery failed"}
    
    def _analyze_user_context(self) -> Dict[str, Any]:
        """Analyse le contexte utilisateur de maniÃ¨re intelligente"""
        try:
            context = {
                "timestamp": datetime.now().isoformat(),
                "system_load": psutil.getloadavg() if hasattr(psutil, 'getloadavg') else None,
                "active_processes": len(psutil.pids()),
                "boot_time": datetime.fromtimestamp(psutil.boot_time()).isoformat()
            }
            
            # Analyse des processus actifs pour dÃ©tecter le contexte
            context["process_analysis"] = self._analyze_running_processes()
            
            # DÃ©tection du mode d'utilisation probable
            context["usage_mode"] = self._infer_usage_mode(context["process_analysis"])
            
            self.logger.log_system_analysis("USER_CONTEXT_ANALYSIS", context)
            return context
            
        except Exception as e:
            self.logger.log_error_with_context(e, {"phase": "user_context_analysis"})
            return {"timestamp": datetime.now().isoformat(), "error": "Context analysis failed"}
    
    def _analyze_running_processes(self) -> Dict[str, Any]:
        """Analyse les processus en cours pour comprendre le contexte"""
        try:
            processes = []
            gaming_indicators = 0
            work_indicators = 0
            development_indicators = 0
            
            for proc in psutil.process_iter(['pid', 'name', 'cpu_percent', 'memory_percent']):
                try:
                    proc_info = proc.info
                    if proc_info['cpu_percent'] > 5 or proc_info['memory_percent'] > 5:  # Processus actifs
                        processes.append(proc_info)
                        
                        # DÃ©tection heuristique du type d'activitÃ©
                        name_lower = proc_info['name'].lower()
                        if any(game_word in name_lower for game_word in ['game', 'steam', 'epic', 'valorant', 'league', 'discord']):
                            gaming_indicators += 1
                        elif any(work_word in name_lower for work_word in ['office', 'word', 'excel', 'teams', 'zoom', 'slack']):
                            work_indicators += 1
                        elif any(dev_word in name_lower for dev_word in ['code', 'visual', 'pycharm', 'git', 'docker', 'python']):
                            development_indicators += 1
                            
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    continue
            
            return {
                "active_processes": processes[:10],  # Top 10 processus actifs
                "gaming_indicators": gaming_indicators,
                "work_indicators": work_indicators,
                "development_indicators": development_indicators,
                "total_analyzed": len(processes)
            }
            
        except Exception as e:
            self.logger.log_error_with_context(e, {"phase": "process_analysis"})
            return {"error": "Process analysis failed"}
    
    def _infer_usage_mode(self, process_analysis: Dict) -> str:
        """InfÃ¨re le mode d'utilisation probable"""
        try:
            gaming = process_analysis.get("gaming_indicators", 0)
            work = process_analysis.get("work_indicators", 0)
            dev = process_analysis.get("development_indicators", 0)
            
            if gaming > work and gaming > dev:
                return "gaming"
            elif work > gaming and work > dev:
                return "work"
            elif dev > gaming and dev > work:
                return "development"
            else:
                return "general"
                
        except Exception:
            return "unknown"
    
    def _calculate_performance_score(self, profiles: Dict) -> float:
        """Calcule un score de performance global"""
        try:
            scores = []
            
            # Score CPU
            if "hardware" in profiles and "cpu" in profiles["hardware"]:
                cpu_score = profiles["hardware"]["cpu"].get("performance_score", 0.5)
                scores.append(cpu_score * 0.3)  # 30% du score total
            
            # Score mÃ©moire
            if "memory" in profiles and "virtual" in profiles["memory"]:
                memory_available = profiles["memory"]["virtual"].get("available_gb", 4)
                memory_score = min(1.0, memory_available / 8)  # NormalisÃ© sur 8GB
                scores.append(memory_score * 0.3)  # 30% du score total
            
            # Score GPU
            if "gpu" in profiles and profiles["gpu"].get("available", False):
                gpu_score = 0.8  # Bonus pour GPU disponible
                scores.append(gpu_score * 0.2)  # 20% du score total
            else:
                scores.append(0.2 * 0.2)  # Score minimal sans GPU
            
            # Score stockage
            if "storage" in profiles and "benchmark" in profiles["storage"]:
                storage_benchmark = profiles["storage"]["benchmark"]
                if "write_speed_mbps" in storage_benchmark and "read_speed_mbps" in storage_benchmark:
                    write_speed = storage_benchmark["write_speed_mbps"]
                    read_speed = storage_benchmark["read_speed_mbps"]
                    storage_score = min(1.0, (write_speed + read_speed) / 200)  # NormalisÃ© sur 100MB/s chaque
                    scores.append(storage_score * 0.2)  # 20% du score total
                else:
                    scores.append(0.3 * 0.2)  # Score moyen sans benchmark
            else:
                scores.append(0.3 * 0.2)  # Score moyen par dÃ©faut
            
            # Score final
            final_score = sum(scores) if scores else 0.5
            return min(1.0, max(0.0, final_score))
            
        except Exception as e:
            return 0.5  # Score neutre en cas d'erreur
    
    def _generate_adaptation_recommendations(self, profiles: Dict) -> List[str]:
        """GÃ©nÃ¨re des recommandations d'adaptation intelligentes"""
        recommendations = []
        
        try:
            # Recommandations Python
            python_profile = profiles.get("python", {})
            if python_profile.get("compatibility", {}).get("score", 1.0) < 0.8:
                recommendations.append("Consider updating Python or installing missing modules")
            
            # Recommandations hardware
            hardware_profile = profiles.get("hardware", {})
            cpu_score = hardware_profile.get("cpu", {}).get("performance_score", 0.5)
            if cpu_score < 0.3:
                recommendations.append("CPU performance is low - consider reducing processing intensity")
            elif cpu_score > 0.8:
                recommendations.append("Excellent CPU performance - can handle intensive processing")
            
            # Recommandations mÃ©moire
            memory_profile = profiles.get("memory", {})
            memory_available = memory_profile.get("virtual", {}).get("available_gb", 4)
            if memory_available < 2:
                recommendations.append("Low memory available - enable memory optimization mode")
            elif memory_available > 8:
                recommendations.append("Abundant memory - can enable high-quality processing")
            
            # Recommandations GPU
            gpu_profile = profiles.get("gpu", {})
            if gpu_profile.get("available", False):
                recommendations.append("GPU detected - enable GPU acceleration for better performance")
            else:
                recommendations.append("No GPU detected - optimize for CPU-only processing")
            
            # Recommandations basÃ©es sur le score global
            performance_score = profiles.get("performance_score", 0.5)
            if performance_score < 0.3:
                recommendations.append("Overall low performance - enable power saving mode")
            elif performance_score > 0.8:
                recommendations.append("High performance system - enable maximum quality settings")
            
        except Exception as e:
            recommendations.append("Error generating recommendations - using default settings")
        
        return recommendations
    
    def _generate_memory_recommendations(self, memory_info: Dict) -> List[str]:
        """GÃ©nÃ¨re des recommandations spÃ©cifiques Ã  la mÃ©moire"""
        recommendations = []
        
        try:
            virtual = memory_info.get("virtual", {})
            percentage = virtual.get("percentage", 50)
            available_gb = virtual.get("available_gb", 4)
            
            if percentage > 80:
                recommendations.append("High memory usage - close unnecessary applications")
            elif percentage < 30:
                recommendations.append("Low memory usage - can increase buffer sizes")
            
            if available_gb < 2:
                recommendations.append("Critical memory shortage - enable aggressive memory optimization")
            elif available_gb > 16:
                recommendations.append("Abundant memory - can enable memory-intensive features")
            
            # Recommandations swap
            swap = memory_info.get("swap", {})
            if swap.get("percentage", 0) > 50:
                recommendations.append("High swap usage - consider adding more RAM")
                
        except Exception:
            recommendations.append("Unable to analyze memory - using default settings")
        
        return recommendations
    
    def _get_fallback_capabilities(self) -> SystemCapabilities:
        """Retourne des capacitÃ©s minimales en cas d'erreur"""
        return SystemCapabilities(
            python_profile={"version": {"major": 3, "minor": 8}, "compatibility": {"score": 0.5}},
            hardware_profile={"cpu": {"cores_logical": 4, "performance_score": 0.5}},
            memory_profile={"virtual": {"total_gb": 8, "available_gb": 4, "percentage": 50}},
            gpu_profile={"available": False, "type": "none"},
            thermal_profile={"monitoring_available": False},
            storage_profile={"disks": []},
            network_profile={"interfaces": []},
            user_context={"usage_mode": "unknown"},
            performance_score=0.5,
            adaptation_recommendations=["Using fallback configuration due to discovery errors"]
        )

# Fonction utilitaire pour crÃ©er le profiler
def create_smart_system_profiler() -> SmartSystemProfiler:
    """CrÃ©e et initialise le profiler systÃ¨me intelligent"""
    return SmartSystemProfiler()

if __name__ == "__main__":
    # Test du profiler
    profiler = SmartSystemProfiler()
    
    print("ğŸ” Test du Smart System Profiler")
    print("=" * 50)
    
    capabilities = profiler.discover_system_capabilities()
    
    print(f"\nğŸ“Š RÃ©sultats de dÃ©couverte:")
    print(f"ğŸ Python: {capabilities.python_profile['version']['version_string']}")
    print(f"ğŸ’» CPU Cores: {capabilities.hardware_profile['cpu']['cores_logical']}")
    print(f"ğŸ’¾ Memory: {capabilities.memory_profile['virtual']['total_gb']:.1f}GB")
    print(f"ğŸ® GPU: {'Available' if capabilities.gpu_profile['available'] else 'Not detected'}")
    print(f"ğŸ“ˆ Performance Score: {capabilities.performance_score:.2f}")
    print(f"ğŸ¯ Usage Mode: {capabilities.user_context['usage_mode']}")
    
    print(f"\nğŸ’¡ Recommandations:")
    for i, rec in enumerate(capabilities.adaptation_recommendations, 1):
        print(f"  {i}. {rec}")
